{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "113bc6ee804b1601"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T17:37:05.067293200Z",
     "start_time": "2024-06-22T17:37:01.688620800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers , models\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.applications import NASNetLarge, NASNetMobile\n",
    "import numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset preparation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "354338ccfd8c0216"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading all the images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e02e9b420edcaa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length benign:  20809\n",
      "Length malign:  4522\n"
     ]
    }
   ],
   "source": [
    "csv_file = pd.read_csv('ISIC_2019_Training_GroundTruth (2).csv')\n",
    "image_path=[]\n",
    "benign_malign = csv_file.iloc[:,1:2]\n",
    "image_name = csv_file.iloc[:,0]\n",
    "dir = \"ISIC_2019_Training_Input\"\n",
    "for names in image_name:\n",
    "    fpath = os.path.join(dir,names +\".jpg\")\n",
    "    image_path.append(fpath)\n",
    "benign=[]\n",
    "mel=[]\n",
    "index = 0\n",
    "for  values in benign_malign.iloc[:,0]:\n",
    "    if values == 0.0:\n",
    "        benign.append(image_path[index])\n",
    "    else:\n",
    "        mel.append(image_path[index])\n",
    "    index+=1\n",
    "print(\"Length benign: \", len(benign))\n",
    "print(\"Length malign: \", len(mel))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T17:03:42.174909500Z",
     "start_time": "2024-06-22T17:03:42.022845300Z"
    }
   },
   "id": "1ad7e5936d867b27",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dividing the images in train , test , valid."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e612b05aa1da046"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign dataset\n",
      "Train set size: 13317\n",
      "Validation set size: 3330\n",
      "Test set size: 4162\n",
      "Melanoma Dataset\n",
      "Train set size: 2893\n",
      "Validation set size: 724\n",
      "Test set size: 905\n"
     ]
    }
   ],
   "source": [
    "#For benign set of images\n",
    "ben_train_paths, ben_test_paths = train_test_split(benign, test_size=0.2, random_state=42)\n",
    "\n",
    "ben_train_paths, ben_val_paths = train_test_split(ben_train_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(\"Benign dataset\")\n",
    "print(\"Train set size:\", len(ben_train_paths))\n",
    "print(\"Validation set size:\", len(ben_val_paths))\n",
    "print(\"Test set size:\", len(ben_test_paths))\n",
    "\n",
    "#For images with melenoma\n",
    "mel_train_paths, mel_test_paths = train_test_split(mel, test_size=0.2, random_state=42)\n",
    "\n",
    "mel_train_paths, mel_val_paths = train_test_split(mel_train_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(\"Melanoma Dataset\")\n",
    "print(\"Train set size:\", len(mel_train_paths))\n",
    "print(\"Validation set size:\", len(mel_val_paths))\n",
    "print(\"Test set size:\", len(mel_test_paths))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T17:03:47.111285600Z",
     "start_time": "2024-06-22T17:03:47.092554900Z"
    }
   },
   "id": "611326b9b040180d",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Folder Segregation\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba553b6d8cc5fb0d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.makedirs(\"test\", exist_ok=True)\n",
    "os.makedirs(\"train\", exist_ok=True)\n",
    "os.makedirs(\"validation\", exist_ok=True)\n",
    "\n",
    "os.makedirs(\"test/\"+ \"benign\", exist_ok=True)\n",
    "os.makedirs(\"test/\"+ \"mel\", exist_ok=True)\n",
    "os.makedirs(\"train/\"+ \"benign\", exist_ok=True)\n",
    "os.makedirs(\"train/\"+ \"mel\", exist_ok=True)\n",
    "os.makedirs(\"validation/\"+ \"benign\", exist_ok=True)\n",
    "os.makedirs(\"validation/\"+ \"mel\", exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:51:38.443854600Z",
     "start_time": "2024-06-22T16:51:38.428805300Z"
    }
   },
   "id": "20540120cc320652",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for file_path in ben_train_paths:\n",
    "    shutil.copy(file_path, \"train/benign/\")\n",
    "for file_path in ben_test_paths:\n",
    "    shutil.copy(file_path, \"test/benign/\")\n",
    "for file_path in ben_val_paths:\n",
    "    shutil.copy(file_path, \"validation/benign/\")\n",
    "for file_path in mel_train_paths:\n",
    "    shutil.copy(file_path, \"train/mel/\")\n",
    "for file_path in mel_test_paths:\n",
    "    shutil.copy(file_path, \"test/mel/\")\n",
    "for file_path in mel_val_paths:\n",
    "    shutil.copy(file_path, \"validation/mel/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:55:57.278760Z",
     "start_time": "2024-06-22T16:51:38.446366Z"
    }
   },
   "id": "e16b1388dffa804e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nbase_model = NASNetMobile(weights=\"imagenet\", include_top=False, input_shape=(331, 331, 3))\\n\\n# Access the output tensor of the pre-trained model\\nx = base_model.output\\n\\n# Add Dense layers for classification\\n\\nx = tf.keras.layers.Dense(units=1, activation=\\'sigmoid\\')(x)\\n\\n# Create a new functional model with the combined layers\\nmodel = models.Model(inputs=base_model.input, outputs=x)\\n'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NasNet\n",
    "# Load the pre-trained model (include_top=False for features)\n",
    "'''\n",
    "base_model = NASNetMobile(weights=\"imagenet\", include_top=False, input_shape=(331, 331, 3))\n",
    "\n",
    "# Access the output tensor of the pre-trained model\n",
    "x = base_model.output\n",
    "\n",
    "# Add Dense layers for classification\n",
    "\n",
    "x = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "# Create a new functional model with the combined layers\n",
    "model = models.Model(inputs=base_model.input, outputs=x)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T17:39:25.588138400Z",
     "start_time": "2024-06-22T17:39:25.565133300Z"
    }
   },
   "id": "c0c6736987a06022",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_url = \"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\"\n",
    "NASNet_mobile = tf.keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))  # Download weights explicitly\n",
    "\n",
    "# Create your classification head\n",
    "model = tf.keras.Sequential([\n",
    "    NASNet_mobile,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),  # Optional hidden layer\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T17:43:13.010684700Z",
     "start_time": "2024-06-22T17:43:11.671708500Z"
    }
   },
   "id": "ef7540fd1c3def7a",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19ac931b3485277b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16210 images belonging to 2 classes.\n",
      "Found 4054 images belonging to 2 classes.\n",
      "1014/1014 [==============================] - 1021s 1s/step - loss: 0.4094 - accuracy: 0.8425 - precision: 0.6534 - recall: 0.2503 - auc: 0.7888 - val_loss: 1.9799 - val_accuracy: 0.8214 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5347\n"
     ]
    }
   ],
   "source": [
    "img_height = img_width = 224\n",
    "batch_size = 16\n",
    "'''\n",
    "# Define the CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (benign/malignant)\n",
    "'''\n",
    "# Compile the model\n",
    "METRICS = [\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
    "    loss=[keras.losses.BinaryCrossentropy(from_logits=False)],\n",
    "    metrics=METRICS,\n",
    ")\n",
    "\n",
    "# Define data generators for training and validation sets (recommended for large datasets)\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create training and validation data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle = True,\n",
    "    seed = 123\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'validation', \n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          epochs=1,  # Adjust number of epochs based on your dataset size\n",
    "          validation_data=val_generator)\n",
    "\n",
    "# Save the model for later use\n",
    "model.save('skin_cancer_detection.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:00:15.578303100Z",
     "start_time": "2024-06-22T17:43:13.351499800Z"
    }
   },
   "id": "647ba6756c8fba12",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-22T16:56:02.360819300Z"
    }
   },
   "id": "12f83a18df557cfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3fe555825bd6ae2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5067 images belonging to 2 classes.\n",
      "159/159 [==============================] - 111s 702ms/step - loss: 1.9792 - accuracy: 0.8214 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5254\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 11\u001B[0m\n\u001B[0;32m      3\u001B[0m test_generator \u001B[38;5;241m=\u001B[39m test_datagen\u001B[38;5;241m.\u001B[39mflow_from_directory(\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Replace with path to your test data folder\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     target_size\u001B[38;5;241m=\u001B[39m(img_height, img_width),\n\u001B[0;32m      6\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m,\n\u001B[0;32m      7\u001B[0m     class_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      8\u001B[0m )\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the test data\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(test_generator)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Print test accuracy\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest accuracy:\u001B[39m\u001B[38;5;124m'\u001B[39m, test_acc)\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load test data generator (similar to training and validation)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'test',  # Replace with path to your test data folder\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print test accuracy\n",
    "print('Test accuracy:', test_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:07:16.365574200Z",
     "start_time": "2024-06-22T18:05:24.107391800Z"
    }
   },
   "id": "6169fa244f4b0071",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
